---
title: "CindexSimulationMetabric2"
output: html_document
date: "2025-02-27"
---

## Concordance index multiverse.


Load libraries

```{r, include=FALSE}
# Survival metrics
library(reticulate)
library(arrow)
library(caret)
library(riskRegression)
library(prodlim)
library(pec)
library(survival)
library(rhdf5)
library(randomForestSRC)
library(survAUC)
library(Hmisc)
library(dplyr)
# Plotting
library(gridExtra)
# Parallelization
library(doFuture)
library(future)
library(progressr)
library(foreach)
library(MASS)
library(flexsurv)
library(furrr)
library(pysurvivalR)
library(survivalmodels)
```


```{r}
#conda create -n py-rstudio python=3.10
#conda activate py-rstudio
#conda config --add channels conda-forge
#conda config --set channel_priority strict
#conda install numpy
#conda install pycox
#conda install lifelines
#conda install numba
#conda install furrr
```


```{r setup, include=FALSE}
#Sys.unsetenv("RETICULATE_PYTHON")
Sys.setenv(OMP_NUM_THREADS = "1")       # Limits OpenMP to 1 thread
Sys.setenv(NUMBA_NUM_THREADS = "1")     # Limits Numba to 1 thread
Sys.setenv(MKL_NUM_THREADS = "1")       # Limits Intel MKL to 1 thread
Sys.setenv(KMP_WARNINGS = "0")          # Disables OpenMP warnings
Sys.setenv(OPENBLAS_NUM_THREADS = "1")  # Limits OpenBLAS to 1 thread

# #Sys.setenv(NUMBA_DISABLE_JIT = "0")  
# library(reticulate)

#use_condaenv("/opt/homebrew/Caskroom/miniforge/base/envs/py-rstudio", required=TRUE)
#use_virtualenv("~/.virtualenvs/venv-DeSurv_python_R")
#use_python("/opt/homebrew/Caskroom/miniforge/base/envs/venv-DeSurv3/bin/python3.9")
#py_config()
```

### Introduction

https://pmc.ncbi.nlm.nih.gov/articles/PMC7731987/
https://cran.r-project.org/web/packages/SurvRegCensCov/vignettes/weibull.pdf
https://onlinelibrary.wiley.com/doi/epdf/10.1002/9781118032985.ch2?saml_referrer
https://en.wikipedia.org/wiki/Weibull_distribution#Alternative_parameterizations
https://www.mas.ncl.ac.uk/~nmf16/teaching/mas3311/week09.pdf

A parametric weibull regression model can be parametrize in various ways. Often the **Weibull accelerated failure time** is used, and can be perfomed with \pkg{survreg} in \prog{R}. The distribution is being cast into a location-scale framework following chapter 2.2 of Kalbfleisch and Prentice: 


$$\log T = Y = \mu + \boldsymbol{\alpha}^T \mathbf{z} + \sigma W,$$
where $\mathbf{z}$ are set of covariates, and $W$ has the extreme value distribution.

However, the alternative Weibull proportional hazard parametrization is more commonly used in medicine and it can be defined in terms of the following baseline hazard: 

$$h(x|\mathbf{z}) = (\gamma \factor.cens t^{\gamma - 1}) \exp(\boldsymbol{\beta}^T \mathbf{z}).$$

where the parameters align with the Weibull AFT as follows: 

\begin{align*}
\gamma & =  1/\sigma, \\
\factor.cens & = \exp(-\mu/\sigma), \\
\boldsymbol{\beta} & = -\boldsymbol{\alpha}/\sigma,
\end{align*}


We can simulate times by using the following:
Then the ratio of times for a covariate with value $z_1$ versus values $z_0$, with parameter estimate $\beta$,  can then be computed as:

The $p$th percentile of the (covariate-adjusted) Weibull distribution occurs at 
$$t_p = \left[ \frac{-\log p}{\factor.cens e^{\boldsymbol{\beta}^T \mathbf{z}}} \right]^{1/\gamma}.$$

```{r}
# Dataset from Deep Surv, also used in DeSurv:
h5_test <- h5read("./Datasets/metabric_IHC4_clinical_train_test.h5", 
                  name="test")

h5_train <- h5read("./Datasets/metabric_IHC4_clinical_train_test.h5",
                   name="train")

# Make a dataset for training:
train <- data.frame(t(h5_train$x))
train$status <- h5_train$e
train$time <- h5_train$t

# Make a dataset for test:
test<- data.frame(t(h5_test$x))
test$status <- h5_test$e
test$time <- h5_test$t

# Order
test <- test[order(test$time, -test$status),]
train <- train[order(train$time, -train$status),]
test$time <- test$time + 1e-8
train$time <- train$time + 1e-8

mb <- rbind(train, test) # for crossvalidation settings
```

```{r}
# read the processed file
mb <- read.table("./Datasets/metabric_preprocess_multiverse.csv", sep="," , header = TRUE)

# Keep the id as index
rownames(mb) <- mb$PATIENT_ID

# Remove the id column
mb <- mb[,2:12]

# Sote the previous colnames to keep track of them
cols <- colnames(mb)

# Asign new column names
newcols <- c("X1", "X2", "X3", "X4","X5", "X6", "X7", "X8", "X9", "time", "status")
colnames(mb) <- newcols

# NO NEED OF SUMING, there is no 0s... 
min(mb$time)
#mb$time <- mb$time + 1e-8

# Order according to time and status
mb[order(mb$time, -mb$status),]


```


```{r}
source("./CindexHelperFunctions.R")
```


```{r}

# Load the synthetic datasets and restore attributes
datasets <- load_synthetic_datasets("./Datasets/Synthetic/10d_synthetic_WT_UTc.rds")

# Check if attributes are retained
#attributes(datasets[[1]][[1]])  # Should return "seed", "factor.cens", "cp"

#datasets <- load_synthetic_datasets("./Datasets/Synthetic_datasets/10d_synthetic_WT_WTc.rds")
```

Range of censoring per factor:

```{r}
cp_list <- c()
for (i in seq_along(datasets)){
  for (j in seq_along(datasets[[i]])) {
    # Extract dataset
    dat <- data.frame(datasets[[i]][[j]])
    cp <- attributes(datasets[[i]][[j]])$cp
  }
   cp_list <- append(cp_list, cp)
}

cp_list
```

```{r}
test <- datasets[[4]][[1]]
```

```{r}
hist(test$observed_time)
```




#### CROSSVALIDATION WEIBULL

Only with CoxPH

```{r, eval=FALSE}

# Weibull
#datasets <- datasets_weibull

set.seed(123)
# We could keep the same folds and indices since the dataframes are the same
# Number of folds
K <- 5  
n <- nrow(datasets[[1]][[1]])  

# List of numeric column for standarization
numeric_cols <- c("X1", "X2", "X3", "X4", "X9")

# Shuffle and create folds
#indices <- sample(seq_len(n))
#folds <- cut(indices, breaks = K, labels = FALSE)

stacked_predictions <- list()
# Loop through datasets
for (i in seq_along(datasets)){
  factor.cens_list <- list()
  
  for (j in seq_along(datasets[[i]])) {
    # Extract dataset
    dat <- data.frame(datasets[[i]][[j]])
    attributes(dat) <- attributes(datasets[[i]][[j]])
    n <- nrow(dat)
    
    if (!any(is.infinite(dat$censoring_time))) {
      folds <- createFolds(dat$status, k = K, list = TRUE) 
    } else {
      indices <- sample(seq_len(n))
      folds <- cut(indices, breaks = K, labels = FALSE)
    }
    # Interesting intervals for prediction
    mb_t_max <- round(max(dat$observed_time))
    ts_scaled <- seq(0, mb_t_max, 1)
    fold_list <- list()
    
    for (k in seq_len(K)) {
      # Define test and training indices
      if (!any(is.infinite(dat$censoring_time))) {
        mb_test_idx  <- folds[[k]]
      } else {
        mb_test_idx  <- which(folds == k)
      }
      mb_train_idx <- setdiff(seq_len(nrow(dat)), mb_test_idx)
          
      # Subset the dataset
      mb_train <- dat[mb_train_idx, ]
      mb_test  <- dat[mb_test_idx, ]
      
      #t_train_max <- max(mb_train$observed_time)
  
      # Scale continuous 
      means <- sapply(mb_train[, numeric_cols], mean)
      sds   <- sapply(mb_train[, numeric_cols], sd)
    
      mb_train[, numeric_cols] <- scale(mb_train[, numeric_cols],
                                        center = means, scale = sds)
      mb_test[, numeric_cols]  <- scale(mb_test[, numeric_cols],
                                        center = means, scale = sds)
    
      #t_train_max <- max(mb_train$time)
      #mb_train$observed_time <- mb_train$observed_time / t_train_max
      #mb_test$observed_time <- mb_test$observed_time / t_train_max
      
      # Extract only the covariates used for predictions
      test_covariates <- mb_test[, c("X1", "X2", "X3", "X4",
                                     "X5", "X6", "X7", "X8", "X9")]
      # intervals for prediction scaled
      #approx_seq <- ts_scaled / t_train_max
      # Fit models
      cat("Dataset:", i, ".", j, '\n')
      cat("Fold:", k, '\n')
      #cat("tmax:", t_train_max, "\n")
      cat('Train set dimensions:', dim(mb_train), '\n')
      cat('Train set event:', mean(mb_train$status == 1)*100, '\n')
      cat('Train set censoring:', mean(mb_train$status == 0)*100, '\n')
      cat('Test set dimensions:', dim(mb_test), '\n')
      cat('Train set event:', mean(mb_test$status == 1)*100, '\n')
      cat('Test set censoring:', mean(mb_test$status == 0)*100, '\n')
      cat('\n')
      
      # 2) Predict risk Cox PH
      # Fit with cox ph
      cox_ph <- survival::coxph(Surv(observed_time, status) ~ X1 + X2 + 
                                  X3 + X4 + X5 + X6 + 
                                  X7 + X8 + X9, 
                                   data = mb_train)
      # Predict survival object
      sf <- survfit(cox_ph, newdata = mb_test)
      surv_cox <- t(sf$surv)
      time_grid <- sf$time #* t_train_max
      #Interpolate
      surv_cox_int <- apply(surv_cox, 1, function(s){
         approx(x = time_grid, y=s, xout = ts_scaled, rule = 2)$y
      })
      
      surv_cox_int <- t(surv_cox_int)
      rownames(surv_cox_int) <- rownames(mb_test)
      colnames(surv_cox_int)  <- ts_scaled
      # Calculate expected mortality
      cox_exp_mort <- rowSums(-log(pmax(surv_cox_int, 1e-10)))
      
      fold_results <- data.frame(dataset = i, 
                                 version = j,
                                 cv_fold = k,
                             patients_ids = rownames(mb_test), 
                             test_time = mb_test$observed_time, ### observed_time now!
                             test_status = mb_test$status,
                             ExpMort.CoxPH = cox_exp_mort,
                             CoxPH = as.data.frame(surv_cox_int),
                             factor.cens = attributes(dat)$incre, 
                             cp = attributes(dat)$cp,
                             seed = attributes(dat)$seed,
                             covariates = test_covariates)
      # Append fold results to the list
      fold_list[[k]] <- fold_results
    
    }
    stacked <- do.call(rbind, fold_list)

    # Save to final list with informative name
    factor.cens_list[[j]] <- stacked
  }
  
  stacked_predictions[[i]] <- factor.cens_list
}

```

```{r}
#saveRDS(stacked_predictions, "./Results/UniformSyntheticStackedPredictions.rds")
```

```{r}
stacked_predictions <- readRDS( "./Results/UniformSyntheticStackedPredictions.rds")
```


#### TEST


```{r}
set.seed(123)

subset_stacked <- stacked_predictions[[1]][[1]]

# Boostrap each dataset 
n_bootstraps <- 100
# Set the size, which is the same for each dataset
dataset_size <- 1000 #Since each dataset has the same number of rows
# Keep the same resample indices across datasets to make it comparable
resample_indices <- replicate(n_bootstraps, 
                              sample(seq_len(dataset_size), 
                                     size = dataset_size, replace = TRUE), 
                              simplify = FALSE)
```


```{r}
test <- bootstrap.metric(metrics.wrapper, 
                                dataset=list(
                                   predicted = 1 - subset_stacked$CoxPH.4,
                                   censoring = subset_stacked$test_status, 
                                   time = subset_stacked$test_time), 
                                implementation = list("sksurv.censored"), 
                                eval.times = NULL,
                                resample_indices = resample_indices)
```

#### BOOTSTRAP:

```{r}
#datasets_per_factor.cens <- unique(stacked_predictions$version)
datasets_per_factor.cens <- 10
```

```{r}
#factor.censs <- unique(stacked_predictions$factor.cens)
factors.cens <- seq(0, 0.4, 0.1)
```

```{r}
#prediction_columns <- colnames(stacked_predictions[,c(1:4)])
```

All datasets are boostraped with a different resample indexes. 


```{r}
#mean(stacked_predictions[(stacked_predictions$factor.cens == 7),]$time)
```


```{r, eval=FALSE}
set.seed(123)
## let's try with 1 only 
subset <- stacked_predictions[[3]]
n_bootstraps <- 100
# select columns
selected_exps <- "ExpMort.CoxPH"
# each dataset in subset of factor.cens 
#results_expm1 <- vector("list", length = datasets_per_factor.cens)
#results_expm2 <- vector("list", length = datasets_per_factor.cens)
results_expm3 <- vector("list", length = datasets_per_factor.cens)
#results_risk <- vector("list", length = datasets_per_factor.cens)
results_surv <- vector("list", length = datasets_per_factor.cens)

cps <- list()
model_names <- "CoxPH"
results_per_factor.cens <- vector("list", length = length(factor.cens))

for (l in seq_along(stacked_predictions)) { 
  cat("Censoring set up ", l, "\n")
  subset <- stacked_predictions[[l]]
  for (dataset in seq_along(subset)) {
    # Get the size of dataset
    dataset_size <- nrow(subset[[dataset]])
    # Get factor.cens 
    factor.cens = unique(subset[[dataset]]$factor.cens)
    # Get censoring-percentage
    cps[[dataset]] = unique(subset[[dataset]]$cp)
    # Create bootstrap samples
    resample_indices <- replicate(n_bootstraps, 
                                    sample(subset[[dataset]]$patients_ids, 
                                           size = dataset_size, 
                                           replace = TRUE), 
                                    simplify = FALSE)
    # When eval is at max uncensored time
    #eval.tau1 <- round(max(subset[[dataset]]$test_time)) # does not matter for C implem
    #eval.tau2 <- 120 # 10 years
    eval.tau3 <- round(max(subset[[dataset]]$test_time[subset[[dataset]]$test_status == 1]))
    
    # Create empty lists
    subset_surv <- list()
    subset_expm <- list()
    
    # Boostrapping
    for (r in seq_along(resample_indices)){
      subset_expm[[r]] <- get_model_preds2(stacked_predictions = subset[[dataset]], 
                   model_names = "CoxPH",
                   input_type = "ExpectedMortality",
                   bootstrap_patient_ids = resample_indices[[r]])

      subset_surv[[r]] <- get_model_preds2(stacked_predictions = subset[[dataset]], 
                  model_names = "CoxPH",
                  input_type = "Distribution",
                  bootstrap_patient_ids = resample_indices[[r]])
    }
    
     for (exps in selected_exps){
        cat("Boostrapping for factor.cens ", factor.cens, ", dataset ", 
           dataset, "and column ", exps, "\n")
        cat("Tau=", eval.tau3 , "\n")
        results_expm3[[dataset]][[exps]] <-  bootstrap.metric.parallel(metrics.wrapper,
                            dataset=list(
                               predicted = exps,
                               censoring = "test_status",
                               time = "test_time"),
                            implementation = list("Hmisc::rcorr.cens",
                                                  "pysurvival",
                                                  "SurvMetrics::Cindex", 
                                                  "lifelines", 
                                                  "sksurv.censored",
                                                  "survC1::Est.Cval", 
                                                  "pec::cindex", 
                                                  "survival.n", 
                                                  "survival.n/G2"),
                            eval.times = eval.tau3, 
                            sampled_data = subset_expm)
      }
    
    for (model in model_names) {
      # Antolinis
      cat("Calculating bootstrap for Distribution for Model = ", model, "\n")
      results_surv[[dataset]][[model]] <-  bootstrap.metric(metrics.wrapper,
                                      dataset=list(
                                         predicted = model,
                                         censoring = "test_status",
                                         time = "test_time"),
                                      implementation = list("pycox.Ant", "pycox.Adj.Ant"),
                                      sampled_data = subset_surv)
    }
  }
  #results_per_factor.cens[[l]] <- list(results_expm1, results_expm2,
  #                                results_expm3, results_surv)
  results_per_factor.cens[[l]] <- list(results_expm3, results_surv)
}



```

```{r}
#saveRDS(results_per_factor.cens, "./Results/UniformSynthetic.rds")

```

```{r}
results_per_factor.cens <- readRDS("./Results/UniformSynthetic.rds")
```


#### Plot

```{r}
all_results <- list()
expm_entries <- list()
surv_entries <- list()

for (l in seq_along(results_per_factor.cens)) {
#  list_exp1 <- results_per_factor.cens[[l]][[1]]
#  list_exp2 <- results_per_factor.cens[[l]][[2]]
  list_exp  <- results_per_factor.cens[[l]][[1]]
  list_surv <- results_per_factor.cens[[l]][[2]]
  
  factor.cens <- factors.cens[[l]]

  # Extract raw entries
#  raw_exp1 <- extract_expm_entries(list_exp1, factor.cens)
#  raw_exp2 <- extract_expm_entries(list_exp2, factor.cens)
  raw_exp <- extract_expm_entries(list_exp, factor.cens)
  raw_surv <- extract_surv_entries(list_surv, factor.cens)

  # Flatten each entry safely
#  expm_entries_1[[l]] <- do.call(rbind, raw_exp1)
#  expm_entries_2[[l]] <- do.call(rbind, raw_exp2)
  expm_entries[[l]] <- do.call(rbind, raw_exp)
  surv_entries[[l]]   <- do.call(rbind, raw_surv)

#  expm_entries_1[[l]]$Notation <- "C"
#  expm_entries_2[[l]]$Notation <- "C_tau_10"
  expm_entries[[l]]$Notation   <- "C_tau"
  surv_entries[[l]]$Notation   <- "C_td"
  
  #all_results[[l]] <- bind_rows(expm_entries_1[[l]], expm_entries_2[[l]], 
  #                              expm_entries_3[[l]], surv_entries[[l]])
  all_results[[l]] <- bind_rows(expm_entries[[l]], surv_entries[[l]])
}
#exp_df <- do.call(rbind, unlist(expm_entries_all, recursive = FALSE))
final_df <- do.call(rbind, all_results)

#saveRDS(final_df, "./Results/SyntheticObjects/10d_c_ind_results_processed_TcW_123.rds")
```

```{r}
# Map the actual percentages of censoring
final_df$cp_value <- cp_list[match(final_df$Lambda, factors.cens)]
```


```{r, fig.width=7, fig.height=6}

ggplot(final_df[(final_df$Notation == "C_tau" | final_df$Notation == "C"),],
       aes(x = as.factor(cp_value), y = Cindex)) +
  geom_violin(alpha = 0.2, color = "black") +
  #geom_errorbar(aes(ymin = Lower, ymax = Upper), position = position_dodge(width = 0.9), width = 0.25) +
  facet_wrap(~Metric) +
  labs(
       y = "C-index",
       x = "Censoring percentage",
       fill = "Input Type") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
```

```{r}
ggplot(final_df[(final_df$Notation == "C_td"),],
       aes(x = as.factor(cp_value), y = Cindex)) +
  geom_violin(alpha = 0.2, color = "black") +
  #geom_errorbar(aes(ymin = Lower, ymax = Upper), position = position_dodge(width = 0.9), width = 0.25) +
  facet_wrap(~Metric) +
  labs(
       y = "C-index",
       x = "Censoring percentage",
       fill = "Input Type") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
```

Looking at the comparable/concordant of survival.n and survival.n/G2

```{r}

extract <- c(
  "survival.n.G2",
  "survival.n.G2.CP",
  "survival.n.G2.DP",
  "survival.n.G2.TR",
  "survival.n.G2.TT",
  "survival.n.G2.TB",
  "survival.n",
  "survival.n.CP",
  "survival.n.DP",
  "survival.n.TR",
  "survival.n.TT",
  "survival.n.TB"
)

```


```{r}
pairs <- list()

expm_entries_3 <- list()

for (l in seq_along(results_per_factor.cens)) {

  list_exp3 <- results_per_factor.cens[[l]][[1]]

  factor.cens <- factors.cens[[l]]

  raw_exp3 <- extract_expm_pairs(list_exp3, factor.cens,  extract = extract)

  pairs[[l]] <- raw_exp3

}

df_pairs <- do.call(rbind, pairs)
df_pairs <- data.frame(lapply(df_pairs, as.numeric))

df_pairs$survival.n.G2.Comparable <- df_pairs$survival.n.G2.CP + df_pairs$survival.n.G2.DP
df_pairs$survival.n.Comparable <- df_pairs$survival.n.CP + df_pairs$survival.n.DP

df_pairs$survival.n.G2.Concordant <- df_pairs$survival.n.G2.CP 
df_pairs$survival.n.Concordant <- df_pairs$survival.n.CP

```


```{r, fig.width=8, fig.height=7}
library(tidyverse)
library(patchwork)
# Example: Assume df_pairs has these columns:
# factor.cens, dataset, survival.n.G2.CompPairs, survival.n.G2.CP, survival.n.CompPairs, survival.n.CP

# Reshape to long format
df_long <- df_pairs[,
  c("survival.n.G2.Concordant", "survival.n.G2.Comparable", 
         "survival.n.Concordant", "survival.n.Comparable", "lambda", "dataset")] %>%
  pivot_longer(
    cols = starts_with("survival.n"),
    names_to = "Metric",
    values_to = "Value"
  ) %>%
  mutate(
    Group = case_when(
      str_detect(Metric, "G2") ~ "survival.n/G2",
      TRUE ~ "survival.n"
    )
  )

df_long <- df_long %>%
  mutate(
    PairType = case_when(
      grepl("Comparable", Metric) ~ "Comparable",
      grepl("Concordant", Metric) ~ "Concordant",
      TRUE ~ "Other"
    )
  )

df_long$Group <- factor(df_long$Group, levels = c(
  "survival.n",
  "survival.n/G2"
))

df_long$cp_value <- cp_list[match(df_long$lambda, factors.cens)]
# First plot
p1 <- ggplot(df_long, aes(x = as.factor(cp_value), y = Value, fill = PairType)) +
  geom_boxplot(alpha = 0.5, outlier.shape = NA) +
  facet_wrap(~Group, scales = "free") +
  scale_fill_manual(values = c("Comparable" = "grey80", "Concordant" = "grey20")) +
  labs(x = "", y = "Number of pairs") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Second plot
p2 <- ggplot(final_df[((final_df$Notation == "C_tau" | final_df$Notation == "C") & 
                         (final_df$Metric == "survival.n" | final_df$Metric == "survival.n/G2")),],  
             aes(x = as.factor(cp_value), y = Cindex)) +
  geom_violin(alpha = 0.4, color = "black") +
  #geom_errorbar(aes(ymin = Lower, ymax = Upper), position = position_dodge(width = 0.9), width = 0.25) +
  facet_wrap(~ Metric) +
  labs( y = "C-index",
       x = "Censoring percentage",
       fill = "Input Type") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Combine vertically
p1 / p2
```




```{r}
ggplot(final_df[(final_df$Notation == "C_td"),],  aes(x = as.factor(Lambda), y = Cindex, fill = Metric)) +
  geom_violin(alpha = 0.4, color = "black") +
  geom_errorbar(aes(ymin = Lower, ymax = Upper), position = position_dodge(width = 0.9), width = 0.25) +
  facet_wrap(~Metric)
  labs(title = "Model Performance per factor.cens",
       y = "C-index",
       x = "factor.cens",
       fill = "Input Type") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
```
```{r}
final_df %>%
  filter(Notation == "C_td") %>%
  group_by(Lambda, Metric) %>%
  summarise(n = n(), .groups = "drop")

```



```{r}
# imp_map <- data.frame(
#   Metric = c("Hmisc::rcorr.cens", "SurvMetrics::Cindex", "lifelines", "pysurvival", 
#              "sksurv.censored", "pec::cindex", "survC1::Est.Cval", "survival.n", 
#              "survival.n/G2", "pycox.Ant", "pycox.Adj.Ant", "sksurv.ipcw"),
#   Implementation = c("Hmisc", "SurvMetrics", "lifelines", "pysurvival", "sksurv.censored",
#   "pec", "survC1", 'survival.n', 'survival.n/G2', 
#   "pycox.Ant", "pycox.Adj.Ant", "sksurv.ipcw"),
#   stringsAsFactors = FALSE
# )
# 
# notation_map <- data.frame(
#   Implementation = c("pycox.Ant", "pycox.Adj.Ant", 
#              "pec", "survC1", "survival.n/G2", "sksurv.ipcw","survival.n", 
#              "Hmisc", "SurvMetrics", "lifelines", "pysurvival", 
#              "sksurv.censored"),
#   Notation = c("C td", "C td", 
#                "C tau", "C tau", "C tau", 
#                "C tau", "C tau",
#                "C", "C", "C", "C", "C"),
#   stringsAsFactors = FALSE
# )
# 
# 
# final_df <- merge(final_df, imp_map, by = "Metric", all.x = TRUE)
# final_df <- merge(final_df, notation_map, by = "Implementation", all.x = TRUE)
```

```{r}

ggplot(final_df[final_df$InputType == "Exp.Mort",],  aes(x = as.factor(Lambda), y = Cindex, fill = Metric)) +
  geom_violin(alpha = 0.4, color = "black") +
  geom_errorbar(aes(ymin = Lower, ymax = Upper), position = position_dodge(width = 0.9), width = 0.25) +
  facet_wrap(~Metric)
  labs(title = "Model Performance per factor.cens",
       y = "C-index",
       x = "factor.cens",
       fill = "Input Type") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
  
ggplot(final_df[final_df$InputType == "Exp.Mort",],  aes(x = as.factor(Lambda), y = Cindex, fill = Metric)) +
  geom_violin(alpha = 0.4, color = "black") +
  geom_errorbar(aes(ymin = Lower, ymax = Upper), position = position_dodge(width = 0.9), width = 0.25) +
  labs(title = "Expected Mortality Cox PH across factor.cens adjustment values",
       y = "C-index",
       x = "factor.cens",
       fill = "Implementation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```
```{r}

final_df$Notation <- ifelse(
  final_df$Metric %in% c("Hmisc::rcorr.cens",
                         "pysurvival", "SurvMetrics::Cindex",
                         "lifelines", "sksurv.censored"),
  "C",
  final_df$Notation
)


ggplot(final_df[final_df$InputType == "Exp.Mort",],  aes(x = as.factor(Lambda), y = Cindex, fill = Metric)) +
  facet_wrap(~ Notation) +
  geom_violin(alpha = 0.4, color = "black") +
  geom_errorbar(aes(ymin = Lower, ymax = Upper), position = position_dodge(width = 0.9), width = 0.25) +
  labs(title = "Expected Mortality Cox PH across factor.cens adjustment values",
       y = "C-index",
       x = "factor.cens",
       fill = "Implementation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
final_df$ipcw <- ifelse(
  final_df$Metric %in% c("Hmisc::rcorr.cens", 
                         "survival.n", "SurvMetrics::Cindex",
                         "lifelines", "sksurv.censored"),
  "unweighted",
  "weighted"
)


ggplot(final_df[final_df$InputType == "Exp.Mort",],  aes(x = as.factor(Lambda), y = Cindex, fill = Metric)) +
  facet_wrap(~ ipcw) +
  geom_violin(alpha = 0.4, color = "black") +
  geom_errorbar(aes(ymin = Lower, ymax = Upper), position = position_dodge(width = 0.9), width = 0.25) +
  labs(title = "Expected Mortality Cox PH across factor.cens adjustment values",
       y = "C-index",
       x = "factor.cens",
       fill = "Implementation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```



```{r}
ggplot(final_df,  aes(x = as.factor(factor.cens), y = Cindex, fill = Metric)) +
  geom_violin(alpha = 0.4, color = "black") +
  geom_errorbar(aes(ymin = Lower, ymax = Upper), position = position_dodge(width = 0.9), width = 0.25) +
  facet_wrap(~InputType)
  labs(title = "Model Performance per factor.cens",
       y = "C-index",
       x = "factor.cens",
       fill = "Input Type") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
```{r}
ggplot(final_df[final_df$Lambda == 0.4,],  
       aes(x = as.factor(cp_value), y = Cindex, fill = Metric)) +
  geom_violin(alpha = 0.4, color = "black") +
  geom_errorbar(aes(ymin = Lower, ymax = Upper), position = position_dodge(width = 0.9), width = 0.25) +
  facet_wrap(~InputType)
  labs(title = "Model Performance per factor.cens",
       y = "C-index",
       x = "factor.cens",
       fill = "Input Type") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
