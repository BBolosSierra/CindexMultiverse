---
title: "CindexSimulationMetabric2"
output: html_document
date: "2025-02-27"
---

## Concordance index multiverse.


Load libraries

```{r Load libraries, include=FALSE}
# Survival metrics
library(reticulate)
library(arrow)
library(caret)
library(riskRegression)
library(prodlim)
library(pec)
library(survival)
library(rhdf5)
library(randomForestSRC)
library(Hmisc)
library(dplyr)
library(gridExtra)
library(doFuture)
library(future)
library(progressr)
library(foreach)
library(MASS)
library(flexsurv)
library(furrr)
library(pysurvivalR)
library(survivalmodels)
```

```{r Setup, include=FALSE}
#Sys.unsetenv("RETICULATE_PYTHON")
Sys.setenv(OMP_NUM_THREADS = "1")       # Limits OpenMP to 1 thread
Sys.setenv(NUMBA_NUM_THREADS = "1")     # Limits Numba to 1 thread
Sys.setenv(MKL_NUM_THREADS = "1")       # Limits Intel MKL to 1 thread
Sys.setenv(KMP_WARNINGS = "0")          # Disables OpenMP warnings
Sys.setenv(OPENBLAS_NUM_THREADS = "1")  # Limits OpenBLAS to 1 thread

# #Sys.setenv(NUMBA_DISABLE_JIT = "0")  
# library(reticulate)

#use_condaenv("/opt/homebrew/Caskroom/miniforge/base/envs/py-rstudio", required=TRUE)
#use_virtualenv("~/.virtualenvs/venv-DeSurv_python_R")
#use_python("/opt/homebrew/Caskroom/miniforge/base/envs/venv-DeSurv3/bin/python3.9")
#py_config()
```

### Introduction

https://pmc.ncbi.nlm.nih.gov/articles/PMC7731987/
https://cran.r-project.org/web/packages/SurvRegCensCov/vignettes/weibull.pdf
https://onlinelibrary.wiley.com/doi/epdf/10.1002/9781118032985.ch2?saml_referrer
https://en.wikipedia.org/wiki/Weibull_distribution#Alternative_parameterizations
https://www.mas.ncl.ac.uk/~nmf16/teaching/mas3311/week09.pdf

A parametric weibull regression model can be parametrize in various ways. Often the **Weibull accelerated failure time** is used, and can be perfomed with \pkg{survreg} in \prog{R}. The distribution is being cast into a location-scale framework following chapter 2.2 of Kalbfleisch and Prentice: 


$$\log T = Y = \mu + \boldsymbol{\alpha}^T \mathbf{z} + \sigma W,$$
where $\mathbf{z}$ are set of covariates, and $W$ has the extreme value distribution.

However, the alternative Weibull proportional hazard parametrization is more commonly used in medicine and it can be defined in terms of the following baseline hazard: 

$$h(x|\mathbf{z}) = (\gamma \lambda t^{\gamma - 1}) \exp(\boldsymbol{\beta}^T \mathbf{z}).$$

where the parameters align with the Weibull AFT as follows: 

\begin{align*}
\gamma & =  1/\sigma, \\
\lambda & = \exp(-\mu/\sigma), \\
\boldsymbol{\beta} & = -\boldsymbol{\alpha}/\sigma,
\end{align*}


We can simulate times by using the following:
Then the ratio of times for a covariate with value $z_1$ versus values $z_0$, with parameter estimate $\beta$,  can then be computed as:

The $p$th percentile of the (covariate-adjusted) Weibull distribution occurs at 
$$t_p = \left[ \frac{-\log p}{\lambda e^{\boldsymbol{\beta}^T \mathbf{z}}} \right]^{1/\gamma}.$$

To estimate the oracle, we need the survival probabilities per patient, per dataset: 

$$S(t|z) = e^{-\lambda t^{\gamma} e^{\beta^{T}z}}$$

Where parameters estimated during the data generation such $gamma$ and $lambda$ are required. Therefore, they are stored during synthetic data generation.

The 100 datasets are generated with the same survreg model. However, we are sampling 1000 patients, and therefore, we do have different covariates per dataset and event times. It is archived by varying the seed, and it is reproducible since all seeds are stored. The observed event times are calculated by including increasing levels of censoring. 
For one dataset, we would have 5 versions of it, with increasing levels of censoring. 
Since one dataset has the same original event times (although different observed times due to censoring), model parameters are kept throughout the process of increasing censoring, regardless of censoring mechanism generation.


```{r Load datasets}
# read the processed file
mb <- read.table("./Datasets/metabric_preprocess_multiverse.csv", 
                 sep = "," , header = TRUE)

# Keep the id as index
rownames(mb) <- mb$PATIENT_ID

# Remove the id column
mb <- mb[,2:12]

# Mapping
var_map <- c(
  "MKI67" = "X1",
  "EGFR" = "X2",
  "ERBB2" = "X3",
  "PGR" = "X4",
  "HORMONE_THERAPY" = "X5",
  "RADIO_THERAPY" = "X6",
  "CHEMOTHERAPY" = "X7",
  "ER_IHC" = "X8",
  "AGE_AT_DIAGNOSIS" = "X9",
  "OS_MONTHS" = "time",
  "OS_STATUS" = "status"
)

# Mapping colnames
names(mb)[names(mb) %in% names(var_map)] <- var_map[names(mb)[names(mb) %in% names(var_map)]]


# Order according to time and status
mb[order(mb$time, -mb$status),]

```


```{r Load functions}
source("./CindexHelperFunctions.R")
```

Survreg models with Weibull AFT parametrization are fit to the metabric data:

```{r Define models}
# censoring times
survreg_model_c <- survreg(Surv(mb[mb$status == 0,]$time) ~ 1, dist="weibull")

#survreg_model_c <- survreg(Surv(time, !status) ~ 1, 
#                            data=mb, dist="weibull")

# survival times
survreg_model <- survreg(Surv(time, status) ~ X1 + X2 + X3 +
                                   X4 + X5 + X6 + X7 + X8 + X9,
                                data = mb[mb$status == 1,], dist="weibull")

#survreg_model <- survreg(Surv(time, status) ~ X1 + X2 + X3 +
#                                   X4 + X5 + X6 + X7 + X8 + X9,
#                                data = mb, dist="weibull")
```


#### Testing events generation:

Generate synthetic event times with the built in function:

```{r Generate event times}
test <- generate_synthetic_event_times(survreg_model = survreg_model,
                               n = 1000, 
                               covariates = mb[, c("X1", "X2", "X3", "X4", 
                          "X5","X6", "X7", "X8", "X9")],
                               seed = 123,
                               verbose = FALSE)


hist(test$time, breaks = 100)
```

To the generated data, we include censoring to calculate the observed event times and the final status. 

```{r Add censoring based on Weibull}

test_Wtc <- add_censoring(my_surv_data = test, 
                          cens.type = "weibull", 
                          cens.params = list(
                            weibull_cens_model = survreg_model_c,
                            lambda_c_factor = 1
                            #cens_limit_admin = max(mb$time)
                          ), seed=123)

# Combine into a dataframe
df_hist <- data.frame(
  value = c(test_Wtc$time, test_Wtc$censoring_time, test_Wtc$observed_time),
  group = rep(c("Event time", "Censoring time", "Observed time"), each = 1000)
)

# Plot with ggplot2
ggplot(df_hist, aes(x = value, fill = group)) +
  geom_histogram(alpha = 0.3, position = "identity", bins = 30, color = "black") +
  scale_fill_manual(values = c("steelblue", "darkorange", "darkgreen")) +
  theme_minimal() +
  labs(title = "Weibull Proportinal Hazards Censoring times",
       x = "Value",
       y = "Frequency",
       fill = "Dataset")


```

To the same test data, we can add censoring based on other mechanisms, such informed Weibull:

```{r Add censoring based on age-informed Weibull}

survreg_model_inform <- survreg(Surv(time, !status) ~ X9,
                           dist="weibull",
                           data = mb[mb$status == 0,])

test_Itc <- add_censoring(
  my_surv_data = test,
  cens.type = "informative",
  cens.params = list(
    weibull_cens_model = survreg_model_inform,
    covariates = test[, c("X9")], 
    lambda_c_factor = 1,
    cens_limit_admin = 300
  ),
  seed = 123
)


# Combine into a dataframe
df_hist <- data.frame(
  value = c(test_Itc$time, test_Itc$censoring_time, test_Itc$observed_time),
  group = rep(c("Event time", "Censoring time", "Observed time"), each = 1000)
)

# Plot with ggplot2
ggplot(df_hist, aes(x = value, fill = group)) +
  geom_histogram(alpha = 0.3, position = "identity", bins = 30, color = "black") +
  scale_fill_manual(values = c("steelblue", "darkorange", "darkgreen")) +
  theme_minimal() +
  labs(title = "Weibull Proportinal Hazards Informative Age",
       x = "Value",
       y = "Frequency",
       fill = "Dataset")

```


Another way of adding censoring is based on Uniform (commonly used):


```{r Add censoring based on Uniform}
test_Utc <- add_censoring(my_surv_data = test, 
                          cens.type = "uniform", 
                          cens.params = list(
                            #cens_limit_admin = max(mb$time),
                            cens_increase_unif = 0  # used only for uniform cens
                          ), seed=123)

# Combine into a dataframe
df_hist <- data.frame(
  value = c(test_Utc$time, test_Utc$censoring_time, test_Utc$observed_time),
  group = rep(c("Event time", "Censoring time", "Observed time"), each = 1000)
)

# Plot with ggplot2
ggplot(df_hist, aes(x = value, fill = group)) +
  geom_histogram(alpha = 0.3, position = "identity", bins = 30, color = "black") +
  scale_fill_manual(values = c("steelblue", "darkorange", "darkgreen")) +
  theme_minimal() +
  labs(title = "Uniform Censoring Times",
       x = "Value",
       y = "Frequency",
       fill = "Dataset")

```


#### Generate 100 datasets with increasing levels of censoring

```{r Generate 100 datasets of 1000 patients, eval=FALSE}
# censoring weibull times model
survreg_model_c <- survreg(Surv(mb[mb$status == 0,]$time) ~ 1, dist="weibull")

# survival event times model
survreg_model <- survreg(Surv(time, status) ~ X1 + X2 + X3 +
                                   X4 + X5 + X6 + X7 + X8 + X9,
                                data = mb[mb$status == 1,], dist="weibull")

# informative censoring times
inform_covs <- c("X9")
survreg_model_inform <- survreg(Surv(time, !status) ~ X9,
                           dist="weibull",
                           data = mb[mb$status == 0,])
# Set up increments
factors <- c(0, 0.5, 1.5, 3, 7, 13)
censoring_increm <- seq(0, 0.5, 0.1)

datasets_weibull <- vector("list", length(factors))  
datasets_uniform <- vector("list", length(censoring_increm))
datasets_inform <- vector("list", length(factors))
# Loop through each censoring factor and generate datasets
for (j in seq_len(100)) {
  seed = sample(1:1e6, 1)
  #seed = seed_list[[1]][[j]] # predefined seed. 
  
  # Run the function with different lambda_c_factor values
  dat <- generate_synthetic_event_times(survreg_model = survreg_model,
                             n = 1000, 
                             covariates = mb[, c("X1", "X2", "X3", 
                                                 "X4","X5","X6", 
                                                 "X7", "X8", "X9")],
                             seed = seed,
                               verbose = FALSE)
  
  for (i in seq_along(factors)) {
    
    cat("Seed: ", seed, "\n ")

    
    cat("Weibull censoring \n")
    ## Create weibull
    datasets_weibull[[i]][[j]] <- add_censoring(my_surv_data = dat,
                          cens.type = "weibull",
                          cens.params = list(
                            weibull_cens_model = survreg_model_c, 
                            lambda_c_factor = factors[[i]]
                          ),
                          seed = seed)
    
    cp <- sum(datasets_weibull[[i]][[j]]$status == 0) /
      nrow(datasets_weibull[[i]][[j]]) * 100
    
    attr(datasets_weibull[[i]][[j]], "seed")    <- seed
    attr(datasets_weibull[[i]][[j]], "lambda")  <- factors[[i]]
    attr(datasets_weibull[[i]][[j]], "cp")      <- cp
    attr(datasets_weibull[[i]][[j]], "lambda0") <- attributes(dat)$lambda0
    attr(datasets_weibull[[i]][[j]], "gamma")   <- attributes(dat)$gamma
    attr(datasets_weibull[[i]][[j]], "beta")    <- attributes(dat)$beta
    attr(datasets_weibull[[i]][[j]], "seed")    <- attributes(dat)$seed
    attr(datasets_weibull[[i]][[j]], "mu")      <- attributes(dat)$mu
    attr(datasets_weibull[[i]][[j]], "sigma")   <- attributes(dat)$sigma
    attr(datasets_weibull[[i]][[j]], "alpha")   <- attributes(dat)$alpha
    
    cat("Lambda: ", factors[[i]], " % Censoring: ", cp, "\n")
    
    cat("Informative Weibull censoring \n")
    cat("Informative covariates: ", inform_covs, "\n")
    ## Create informative censoring weibull
    datasets_inform[[i]][[j]] <- add_censoring(my_surv_data = dat,
                          cens.type = "informative",
                          cens.params = list(
                            weibull_cens_model = survreg_model_inform, 
                            lambda_c_factor = factors[[i]],
                            covariates = dat[, inform_covs]
                          ),
                          seed = seed)
    
    cp <- sum(datasets_inform[[i]][[j]]$status == 0) /
      nrow(datasets_inform[[i]][[j]]) * 100
    
    attr(datasets_inform[[i]][[j]], "seed") <- seed
    attr(datasets_inform[[i]][[j]], "lambda") <- factors[[i]]
    attr(datasets_inform[[i]][[j]], "cp") <- cp
    attr(datasets_weibull[[i]][[j]], "lambda0") <- attributes(dat)$lambda0
    attr(datasets_weibull[[i]][[j]], "gamma")   <- attributes(dat)$gamma
    attr(datasets_weibull[[i]][[j]], "beta")    <- attributes(dat)$beta
    attr(datasets_weibull[[i]][[j]], "seed")    <- attributes(dat)$seed
    attr(datasets_weibull[[i]][[j]], "mu")      <- attributes(dat)$mu
    attr(datasets_weibull[[i]][[j]], "sigma")   <- attributes(dat)$sigma
    attr(datasets_weibull[[i]][[j]], "alpha")   <- attributes(dat)$alpha
    
    cat("Lambda: ", factors[[i]], " % Censoring: ", cp, "\n")
    
    cat("Uniform censoring \n")
    ## Create Uniform
    datasets_uniform[[i]][[j]] <- add_censoring(my_surv_data = dat,
                          cens.type = "uniform",
                          cens.params = list(
                            cens_increase_unif = censoring_increm[[i]]
                          ),
                          seed = seed)
    cp <- sum(datasets_uniform[[i]][[j]]$status == 0) /
      nrow(datasets_uniform[[i]][[j]]) * 100

    attr(datasets_uniform[[i]][[j]], "seed") <- seed
    attr(datasets_uniform[[i]][[j]], "incre") <- censoring_increm[[i]]
    attr(datasets_uniform[[i]][[j]], "cp") <- cp
    attr(datasets_weibull[[i]][[j]], "lambda0") <- attributes(dat)$lambda0
    attr(datasets_weibull[[i]][[j]], "gamma")   <- attributes(dat)$gamma
    attr(datasets_weibull[[i]][[j]], "beta")    <- attributes(dat)$beta
    attr(datasets_weibull[[i]][[j]], "seed")    <- attributes(dat)$seed
    attr(datasets_weibull[[i]][[j]], "mu")      <- attributes(dat)$mu
    attr(datasets_weibull[[i]][[j]], "sigma")   <- attributes(dat)$sigma
    attr(datasets_weibull[[i]][[j]], "alpha")   <- attributes(dat)$alpha
    
    cat("Increment: ", censoring_increm[[i]], " % Censoring: ", cp, "\n")
    
    
  }  
}



```

```{r Save dataset in a structured way, eval=FALSE}

# Save datasets along with attributes in a structured list
structured_datasets_weibull <- list(
  data = datasets_weibull,  # Store the datasets
  attributes = lapply(datasets_weibull, function(factor_list) {
    lapply(factor_list, function(dataset) {
      attributes(dataset)  # Extract attributes of each dataset
    })
  })
)

structured_datasets_uniform <- list(
  data = datasets_uniform,  # Store the datasets
  attributes = lapply(datasets_uniform, function(increm_list) {
    lapply(increm_list, function(dataset) {
      attributes(dataset)  # Extract attributes of each dataset
    })
  })
)


structured_datasets_inform <- list(
  data = datasets_inform,  # Store the datasets
  attributes = lapply(datasets_inform, function(factor_list) {
    lapply(factor_list, function(dataset) {
      attributes(dataset)  # Extract attributes of each dataset
    })
  })
)

# Save the structured list as RDS
saveRDS(structured_datasets_weibull, "./Datasets/Synthetic/10d_synthetic_WT_WTc.rds")
saveRDS(structured_datasets_uniform, "./Datasets/Synthetic/10d_synthetic_WT_UTc.rds")
saveRDS(structured_datasets_inform, "./Datasets/Synthetic/10d_synthetic_WT_ITc.rds")

```


To get the list of seeds used to generate stored datasets: 

```{r load simulated datasets}
# Load the synthetic datasets and restore attributes
datasets <- load_synthetic_datasets("./Datasets/Synthetic/10d_synthetic_WT_WTc.rds")

datasets_per_lambda <- 100
factors <- c(0, 0.5, 1.5, 3, 7, 13)
```


```{r Seed list}
seed_list <- vector("list", length(factors))
for (i in seq_along(datasets)){
  for (j in seq_along(datasets[[i]])) {
    # Extract data set
    dat <- data.frame(datasets[[i]][[j]])
    attributes(dat) <- attributes(datasets[[i]][[j]])
    print(attributes(dat)$seed)
    # Print betas
    seed_list[[i]][[j]] <- attributes(dat)$seed
  }
}
```
