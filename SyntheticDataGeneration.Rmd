---
title: "CindexSimulationMetabric2"
output: html_document
date: "2025-02-27"
---

## Concordance index multiverse.


Load libraries

```{r, include=FALSE}
# Survival metrics
library(reticulate)
library(arrow)
library(caret)
library(riskRegression)
library(prodlim)
library(pec)
library(survival)
library(rhdf5)
library(randomForestSRC)
library(survAUC)
library(Hmisc)
library(dplyr)
# Plotting
library(gridExtra)
# Parallelization
library(doFuture)
library(future)
library(progressr)
library(foreach)
library(MASS)
library(flexsurv)
library(furrr)
library(pysurvivalR)
library(survivalmodels)
```


```{r}
#conda create -n py-rstudio python=3.10
#conda activate py-rstudio
#conda config --add channels conda-forge
#conda config --set channel_priority strict
#conda install numpy
#conda install pycox
#conda install lifelines
#conda install numba
#conda install furrr
```


```{r setup, include=FALSE}
#Sys.unsetenv("RETICULATE_PYTHON")
Sys.setenv(OMP_NUM_THREADS = "1")       # Limits OpenMP to 1 thread
Sys.setenv(NUMBA_NUM_THREADS = "1")     # Limits Numba to 1 thread
Sys.setenv(MKL_NUM_THREADS = "1")       # Limits Intel MKL to 1 thread
Sys.setenv(KMP_WARNINGS = "0")          # Disables OpenMP warnings
Sys.setenv(OPENBLAS_NUM_THREADS = "1")  # Limits OpenBLAS to 1 thread

# #Sys.setenv(NUMBA_DISABLE_JIT = "0")  
# library(reticulate)

#use_condaenv("/opt/homebrew/Caskroom/miniforge/base/envs/py-rstudio", required=TRUE)
#use_virtualenv("~/.virtualenvs/venv-DeSurv_python_R")
#use_python("/opt/homebrew/Caskroom/miniforge/base/envs/venv-DeSurv3/bin/python3.9")
#py_config()
```

### Introduction

https://pmc.ncbi.nlm.nih.gov/articles/PMC7731987/
https://cran.r-project.org/web/packages/SurvRegCensCov/vignettes/weibull.pdf
https://onlinelibrary.wiley.com/doi/epdf/10.1002/9781118032985.ch2?saml_referrer
https://en.wikipedia.org/wiki/Weibull_distribution#Alternative_parameterizations
https://www.mas.ncl.ac.uk/~nmf16/teaching/mas3311/week09.pdf

A parametric weibull regression model can be parametrize in various ways. Often the **Weibull accelerated failure time** is used, and can be perfomed with \pkg{survreg} in \prog{R}. The distribution is being cast into a location-scale framework following chapter 2.2 of Kalbfleisch and Prentice: 


$$\log T = Y = \mu + \boldsymbol{\alpha}^T \mathbf{z} + \sigma W,$$
where $\mathbf{z}$ are set of covariates, and $W$ has the extreme value distribution.

However, the alternative Weibull proportional hazard parametrization is more commonly used in medicine and it can be defined in terms of the following baseline hazard: 

$$h(x|\mathbf{z}) = (\gamma \lambda t^{\gamma - 1}) \exp(\boldsymbol{\beta}^T \mathbf{z}).$$

where the parameters align with the Weibull AFT as follows: 

\begin{align*}
\gamma & =  1/\sigma, \\
\lambda & = \exp(-\mu/\sigma), \\
\boldsymbol{\beta} & = -\boldsymbol{\alpha}/\sigma,
\end{align*}


We can simulate times by using the following:
Then the ratio of times for a covariate with value $z_1$ versus values $z_0$, with parameter estimate $\beta$,  can then be computed as:

The $p$th percentile of the (covariate-adjusted) Weibull distribution occurs at 
$$t_p = \left[ \frac{-\log p}{\lambda e^{\boldsymbol{\beta}^T \mathbf{z}}} \right]^{1/\gamma}.$$

```{r}
# Dataset from Deep Surv, also used in DeSurv:
h5_test <- h5read("./Datasets/metabric_IHC4_clinical_train_test.h5", 
                  name="test")

h5_train <- h5read("./Datasets/metabric_IHC4_clinical_train_test.h5",
                   name="train")

# Make a dataset for training:
train <- data.frame(t(h5_train$x))
train$status <- h5_train$e
train$time <- h5_train$t

# Make a dataset for test:
test<- data.frame(t(h5_test$x))
test$status <- h5_test$e
test$time <- h5_test$t

# Order
test <- test[order(test$time, -test$status),]
train <- train[order(train$time, -train$status),]
test$time <- test$time + 1e-8
train$time <- train$time + 1e-8

mb <- rbind(train, test) # for crossvalidation settings
```

```{r}
# read the processed file
mb <- read.table("./Datasets/metabric_preprocess_multiverse.csv", sep="," , header = TRUE)

# Keep the id as index
rownames(mb) <- mb$PATIENT_ID

# Remove the id column
mb <- mb[,2:12]

# Sote the previous colnames to keep track of them
cols <- colnames(mb)

# Asign new column names
newcols <- c("X1", "X2", "X3", "X4","X5", "X6", "X7", "X8", "X9", "time", "status")
colnames(mb) <- newcols

# NO NEED OF SUMING, there is no 0s... 
min(mb$time)
#mb$time <- mb$time + 1e-8

# Order according to time and status
mb[order(mb$time, -mb$status),]


```


```{r}
source("./CindexHelperFunctions.R")
```

```{r}
# censoring times
survreg_model_c <- survreg(Surv(mb[mb$status == 0,]$time) ~ 1, dist="weibull")

#survreg_model_c <- survreg(Surv(time, !status) ~ 1, 
#                            data=mb, dist="weibull")

# survival times
survreg_model <- survreg(Surv(time, status) ~ X1 + X2 + X3 +
                                   X4 + X5 + X6 + X7 + X8 + X9,
                                data = mb[mb$status == 1,], dist="weibull")

#survreg_model <- survreg(Surv(time, status) ~ X1 + X2 + X3 +
#                                   X4 + X5 + X6 + X7 + X8 + X9,
#                                data = mb, dist="weibull")


```

Geneate synthetic event times


```{r}
test <- generate_synthetic_event_times(survreg_model = survreg_model,
                               n = 1000, 
                               covariates = mb[, c("X1", "X2", "X3", "X4", 
                          "X5","X6", "X7", "X8", "X9")],
                               seed = 123,
                               verbose = FALSE)

```


```{r}
hist(test$time, breaks = 100)
```

```{r}
test_Wtc <- add_censoring(my_surv_data = test, 
                          cens.type = "weibull", 
                          cens.params = list(
                            weibull_cens_model = survreg_model_c,
                            lambda_c_factor = 1
                            #cens_limit_admin = max(mb$time)
                          ), seed=123)

# Combine into a dataframe
df_hist <- data.frame(
  value = c(test_Wtc$time, test_Wtc$censoring_time, test_Wtc$observed_time),
  group = rep(c("Event time", "Censoring time", "Observed time"), each = 1000)
)

# Plot with ggplot2
ggplot(df_hist, aes(x = value, fill = group)) +
  geom_histogram(alpha = 0.3, position = "identity", bins = 30, color = "black") +
  scale_fill_manual(values = c("steelblue", "darkorange", "darkgreen")) +
  theme_minimal() +
  labs(title = "Weibull Proportinal Hazards Censoring times",
       x = "Value",
       y = "Frequency",
       fill = "Dataset")


```
```{r}
survreg_model_c <- survreg(Surv(time, !status) ~ I(X9 < threshold),
                           dist="weibull",
                           data = mb[mb$status == 0,])

threshold <- median(mb$X9)

survreg_low <- survreg(Surv(time, !status) ~ 1, 
                       data = mb[mb$X9 < threshold, ], dist = "weibull")

survreg_high <- survreg(Surv(time, !status) ~ 1, 
                        data = mb[mb$X9 >= threshold, ], dist = "weibull")


test_Itc <- add_censoring(
  my_surv_data = test,
  cens.type = "informative2",
  cens.params = list(
    weibull_cens_model_low = survreg_low,
    weibull_cens_model_high = survreg_high,
    covariates = test[, c("X9")]
  ),
  seed = 123
)
```


Another way of adding the informative censoring:

```{r}

# informative censoring times
survreg_model_inform <- survreg(Surv(time, !status) ~  
                                 X6 + X7 + X9, ## rounded otherwise no converge
                                data = mb, dist="weibull")
# 
# survreg_model_inform <- survreg(Surv(time, !status) ~  
#                                  X6 + X7 + X9, ## rounded otherwise no converge
#                                 data = mb, dist="weibull")



test_Itc <- add_censoring(my_surv_data = test, 
                          cens.type = "informative", 
                          cens.params = list(
                            weibull_cens_model = survreg_model_inform,
                            lambda_c_factor = 1,
                            covariates = test[, c(
                          "X6", "X7", "X9")]
                          ), seed=123)

# Combine into a dataframe
df_hist <- data.frame(
  value = c(test_Wtc$time, test_Wtc$censoring_time, test_Wtc$observed_time),
  group = rep(c("Event time", "Censoring time", "Observed time"), each = 1000)
)

# Plot with ggplot2
ggplot(df_hist, aes(x = value, fill = group)) +
  geom_histogram(alpha = 0.3, position = "identity", bins = 30, color = "black") +
  scale_fill_manual(values = c("steelblue", "darkorange", "darkgreen")) +
  theme_minimal() +
  labs(title = "Weibull Proportinal Hazards Informative Censoring  \n (Age, Radiotherapy and Chemotherapy)",
       x = "Value",
       y = "Frequency",
       fill = "Dataset")


```



```{r}
test_Utc <- add_censoring(my_surv_data = test, 
                          cens.type = "uniform", 
                          cens.params = list(
                            #cens_limit_admin = max(mb$time),
                            #min_cens_unif = NULL, # used only for uniform cens
                            #max_cens_unif = NULL, # used only for uniform cens
                            cens_increase_unif = 0  # used only for uniform cens
                          ), seed=123)

# Combine into a dataframe
df_hist <- data.frame(
  value = c(test_Utc$time, test_Utc$censoring_time, test_Utc$observed_time),
  group = rep(c("Event time", "Censoring time", "Observed time"), each = 1000)
)

# Plot with ggplot2
ggplot(df_hist, aes(x = value, fill = group)) +
  geom_histogram(alpha = 0.3, position = "identity", bins = 30, color = "black") +
  scale_fill_manual(values = c("steelblue", "darkorange", "darkgreen")) +
  theme_minimal() +
  labs(title = "Uniform Censoring Times",
       x = "Value",
       y = "Frequency",
       fill = "Dataset")



```



```{r, eval=FALSE}
# censoring times
survreg_model_c <- survreg(Surv(mb[mb$status == 0,]$time) ~ 1, dist="weibull")
# survreg_model_c <- survreg(Surv(time, !status) ~ 1, 
#                            data=mb, dist="weibull")

# survival times
survreg_model <- survreg(Surv(time, status) ~ X1 + X2 + X3 +
                                   X4 + X5 + X6 + X7 + X8 + X9,
                                data = mb[mb$status == 1,], dist="weibull")

# survreg_model <- survreg(Surv(time, status) ~ X1 + X2 + X3 + 
#                                    X4 + X5 + X6 + X7 + X8 + X9, 
#                                 data = mb, dist="weibull")

# informative censoring times
inform_covs <- c("X6", "X7", "X9")
# survreg_model_inform <- survreg(Surv(time, status) ~  
#                                  X6 + X7 + X9, 
#                                 data = mb[mb$status == 0,], dist="weibull")

survreg_model_inform <- survreg(Surv(time, !status) ~  
                                 X6 + X7 + X9, ## rounded otherwise no converge
                                data = mb, dist="weibull")

# Set up increments
factors <- c(0, 0.5, 1.5, 3, 7)
censoring_increm <- seq(0, 0.4, 0.1)

datasets_weibull <- vector("list", length(factors))  
datasets_uniform <- vector("list", length(censoring_increm))
datasets_inform <- vector("list", length(factors))
# Loop through each censoring factor and generate datasets
for (i in seq_along(factors)) {
  for (j in seq_len(10)) {
    seed = sample(1:1e6, 1)
    cat("Seed: ", seed, "\n ")
    # Run the function with different lambda_c_factor values
    dat <- generate_synthetic_event_times(survreg_model = survreg_model,
                               n = 1000, 
                               covariates = mb[, c("X1", "X2", "X3", 
                                                   "X4","X5","X6", 
                                                   "X7", "X8", "X9")],
                               seed = 123,
                               verbose = FALSE)
    
    cat("Weibull censoring \n")
    ## Create weibull
    datasets_weibull[[i]][[j]] <- add_censoring(my_surv_data = dat,
                          cens.type = "weibull",
                          cens.params = list(
                            weibull_cens_model = survreg_model_c, 
                            lambda_c_factor = factors[[i]]
                          ),
                          seed = 123)
    
    cp <- sum(datasets_weibull[[i]][[j]]$status == 0) /
      nrow(datasets_weibull[[i]][[j]]) * 100
    
    attr(datasets_weibull[[i]][[j]], "seed") <- seed
    attr(datasets_weibull[[i]][[j]], "lambda") <- factors[[i]]
    attr(datasets_weibull[[i]][[j]], "cp") <- cp
    
    cat("Lambda: ", factors[[i]], " % Censoring: ", cp, "\n")
    
    cat("Informative Weibull censoring \n")
    cat("Informative covariates: ", inform_covs, "\n")
    ## Create informative censoring weibull
    datasets_inform[[i]][[j]] <- add_censoring(my_surv_data = dat,
                          cens.type = "informative",
                          cens.params = list(
                            weibull_cens_model = survreg_model_inform, 
                            lambda_c_factor = factors[[i]],
                            covariates = dat[, inform_covs]
                          ),
                          seed = 123)
    
    cp <- sum(datasets_inform[[i]][[j]]$status == 0) /
      nrow(datasets_inform[[i]][[j]]) * 100
    
    attr(datasets_inform[[i]][[j]], "seed") <- seed
    attr(datasets_inform[[i]][[j]], "lambda") <- factors[[i]]
    attr(datasets_inform[[i]][[j]], "cp") <- cp
    
    cat("Lambda: ", factors[[i]], " % Censoring: ", cp, "\n")
    
    cat("Uniform censoring \n")
    ## Create Uniform
    datasets_uniform[[i]][[j]] <- add_censoring(my_surv_data = dat,
                          cens.type = "uniform",
                          cens.params = list(
                            cens_increase_unif = censoring_increm[[i]]
                          ),
                          seed = 123)
    cp <- sum(datasets_uniform[[i]][[j]]$status == 0) /
      nrow(datasets_uniform[[i]][[j]]) * 100

    attr(datasets_uniform[[i]][[j]], "seed") <- seed
    attr(datasets_uniform[[i]][[j]], "incre") <- censoring_increm[[i]]
    attr(datasets_uniform[[i]][[j]], "cp") <- cp
    
    cat("Increment: ", censoring_increm[[i]], " % Censoring: ", cp, "\n")
    
    
  }  
}



```

```{r, eval=FALSE}

# Save datasets along with attributes in a structured list
structured_datasets_weibull <- list(
  data = datasets_weibull,  # Store the datasets
  attributes = lapply(datasets_weibull, function(factor_list) {
    lapply(factor_list, function(dataset) {
      attributes(dataset)  # Extract attributes of each dataset
    })
  })
)

structured_datasets_uniform <- list(
  data = datasets_uniform,  # Store the datasets
  attributes = lapply(datasets_uniform, function(increm_list) {
    lapply(increm_list, function(dataset) {
      attributes(dataset)  # Extract attributes of each dataset
    })
  })
)


structured_datasets_inform <- list(
  data = datasets_inform,  # Store the datasets
  attributes = lapply(datasets_inform, function(factor_list) {
    lapply(factor_list, function(dataset) {
      attributes(dataset)  # Extract attributes of each dataset
    })
  })
)
# Save the structured list as RDS
# saveRDS(structured_datasets_weibull, "./Datasets/Synthetic/10d_synthetic_WT_WTc.rds")
# saveRDS(structured_datasets_uniform, "./Datasets/Synthetic/10d_synthetic_WT_UTc.rds")
#saveRDS(structured_datasets_inform, "./Datasets/Synthetic/10d_synthetic_WT_ITc.rds")

```


